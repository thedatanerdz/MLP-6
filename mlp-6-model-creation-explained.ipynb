{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom imblearn.combine import SMOTEENN","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This line imports the metrics module from the sklearn library (Scikit-learn). Scikit-learn is a widely used library for machine learning in Python, and the metrics module provides various functions to evaluate the performance of machine learning models. This line imports the train_test_split function from the model_selection module of Scikit-learn. The train_test_split function is commonly used to split a dataset into training and testing subsets for machine learning tasks. These lines import specific functions from the metrics module in Scikit-learn. recall_score is a function to calculate the recall metric for classification tasks. classification_report is a function that generates a detailed report containing various evaluation metrics for a classification model. confusion_matrix is a function that computes a confusion matrix to evaluate the performance of a classification model. This line imports the DecisionTreeClassifier class from the tree module of Scikit-learn. DecisionTreeClassifier is an implementation of the decision tree algorithm for classification tasks. This line imports the SMOTEENN class from the combine module of the imblearn library. imblearn is a library used for handling imbalanced datasets in machine learning. SMOTEENN is a hybrid sampling technique that combines the SMOTE (Synthetic Minority Over-sampling Technique) and ENN (Edited Nearest Neighbors) algorithms to address class imbalance.\n\nOverall, this code imports necessary libraries and modules for data manipulation, model evaluation, classification, and handling imbalanced datasets. It sets up the environment for further data analysis and machine learning tasks.","metadata":{}},{"cell_type":"markdown","source":"#### Reading csv","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"tel_churn.csv\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop('Unnamed: 0',axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df.drop('Churn',axis=1)\nx","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df['Churn']\ny","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In above code snippet , it appears that df is a pandas DataFrame object, and Churn is one of the columns in that DataFrame. The code y = df['Churn'] assigns the values of the 'Churn' column to the variable y.\n\nIn other words, y now contains a pandas Series object that represents the 'Churn' column from the DataFrame df. This is often done in machine learning tasks to separate the target variable (in this case, the 'Churn' column) from the rest of the data, as the target variable is typically the variable we want to predict or analyze.","metadata":{}},{"cell_type":"markdown","source":"##### Train Test Split","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) uses the train_test_split function from the Scikit-learn library to split the data into training and testing sets.\n\nHere's what each variable represents:\n\nx represents the features or input data that will be used to train the model.\ny represents the target variable or the output that we want to predict or analyze.\ntest_size=0.2 specifies that 20% of the data should be allocated for testing, while the remaining 80% will be used for training.\nAfter executing this line of code, four new variables are created:\n\nx_train contains the training data for the features.\nx_test contains the testing data for the features.\ny_train contains the training data for the target variable.\ny_test contains the testing data for the target variable.\nBy splitting the data into training and testing sets, we can train a machine learning model using the x_train and y_train data and then evaluate its performance on the unseen data using the x_test and y_test data. This helps us assess how well the model generalizes to new, unseen data.","metadata":{}},{"cell_type":"markdown","source":"#### Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"model_dt=DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=6, min_samples_leaf=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code model_dt = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=6, min_samples_leaf=8) creates an instance of the DecisionTreeClassifier class from the Scikit-learn library and assigns it to the variable model_dt.\n\nHere's an explanation of the parameters used in the DecisionTreeClassifier constructor:\n\n* criterion=\"gini\": This parameter specifies the criterion to measure the quality of a split. In this case, \"gini\" is used, which refers to the Gini impurity. Other options include \"entropy\" for information gain.\n* random_state=100: This parameter sets the random seed for reproducibility. It ensures that the same random splits are generated each time the model is trained, allowing for consistent results.\n* max_depth=6: This parameter limits the maximum depth of the decision tree. It controls the complexity of the tree and helps prevent overfitting. In this case, the maximum depth is set to 6.\n* min_samples_leaf=8: This parameter sets the minimum number of samples required to be at a leaf node. It helps prevent the tree from growing too deep and captures smaller subsets of the data. In this case, the minimum samples per leaf is set to 8.\n\nBy creating an instance of the DecisionTreeClassifier with these parameter values, we are specifying the configuration for the decision tree model. This model can be trained on the data using the fit() method and then used to make predictions on new data.","metadata":{}},{"cell_type":"markdown","source":"Overfitting is a common problem in machine learning where a model learns the training data too well, to the point that it starts to perform poorly on unseen or new data. In other words, an overfit model has \"memorized\" the training data and fails to generalize well to unknown examples.\n\nHere are some key characteristics and consequences of overfitting:\n\n* High Training Accuracy, Low Test Accuracy: An overfit model often achieves a high accuracy or performance on the training data because it has learned the specific patterns and noise present in that data. However, when evaluated on new data (test data), the accuracy drops significantly.\n* Complex Model: Overfitting can occur when the model becomes too complex, capturing noise or irrelevant patterns in the training data. It may have a large number of parameters or a high degree of freedom, making it highly flexible in fitting the training data.\n* Lack of Generalization: The primary issue with overfitting is that the model fails to generalize well to unseen data. It becomes overly sensitive to the training data, making it less effective at making accurate predictions on new examples.\n* Poor Performance on Unseen Data: When an overfit model encounters new data that it hasn't seen during training, it may struggle to make accurate predictions. It may produce unreliable and misleading results, which can lead to poor decision-making in real-world applications.\n\nTo address overfitting, several techniques can be employed, including:\n\n*  Simplifying the model: Reducing the complexity of the model, such as by decreasing the number of parameters or using simpler algorithms, can help mitigate overfitting.\n*  Regularization: Techniques like L1 or L2 regularization can be applied to add a penalty term to the model's loss function, discouraging excessive complexity and reducing overfitting.\n*  Cross-validation: Using cross-validation techniques can help assess the model's performance on multiple subsets of the data, providing a more robust evaluation of its generalization ability.\n*  Increasing training data: Providing more diverse and representative training data can help the model learn better and reduce overfitting by capturing a broader range of patterns.\n\nBy addressing overfitting, a model can achieve better generalization and perform well on unseen data, which is crucial for real-world applications and reliable predictions.","metadata":{}},{"cell_type":"markdown","source":"In a machine learning decision tree, a leaf (also referred to as a terminal node) is a node that does not split further. It represents a final prediction or a class label assigned to a subset of the data. Each leaf node in a decision tree corresponds to a specific outcome or decision.\n\nWhen constructing a decision tree, the internal nodes represent features or attributes used for splitting the data, and the leaf nodes represent the final decision or prediction based on those splits.\n\nIn a classification task, each leaf node represents a specific class label or category that the model assigns to the instances that reach that node. For example, in a binary classification problem where the goal is to classify whether an email is spam or not, a leaf node could represent either the \"spam\" class or the \"not spam\" class.\n\nIn a regression task, the leaf nodes represent the predicted continuous values for the instances that reach those nodes. For example, in a decision tree predicting house prices based on features such as size and location, a leaf node may represent a specific predicted house price.\n\nRegarding \"gini\" in machine learning, it refers to the Gini impurity. Gini impurity is a measure of impurity or disorder used in decision tree algorithms to determine the quality of a split. It quantifies the likelihood of misclassifying a randomly chosen element from the dataset if it were randomly labeled according to the class distribution in the subset.\n\nIn the context of decision trees, the Gini impurity is calculated for each potential split on a feature, and the split with the lowest Gini impurity is chosen as the best split. The goal is to minimize the Gini impurity and create splits that separate the data into pure or homogeneous subsets in terms of the target variable.\n\nA Gini impurity value of 0 indicates a completely pure node where all instances belong to the same class, while a value of 0.5 represents maximum impurity, indicating an equal distribution of instances across different classes.\n\nThe \"gini\" criterion is commonly used in decision tree algorithms, such as the CART (Classification and Regression Trees) algorithm, to determine the splitting criteria and build the tree based on minimizing impurity or maximizing information gain.","metadata":{}},{"cell_type":"code","source":"model_dt.fit(x_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code model_dt.fit(x_train, y_train) trains the decision tree model (model_dt) using the training data (x_train and y_train). The fit() method is a common function in machine learning libraries that trains a model on the provided data.\n\nIn this case, the fit() method is called on the model_dt object, which is an instance of the DecisionTreeClassifier class. The x_train parameter represents the training features, which are the input variables used to make predictions. The y_train parameter represents the corresponding target variable or the expected output for each training instance.\n\nBy calling fit(x_train, y_train), the decision tree model is trained to learn the patterns and relationships between the features (x_train) and the target variable (y_train). It adjusts its internal parameters based on the training data, optimizing itself to make accurate predictions.\n\nAfter the training process is complete, the decision tree model (model_dt) is ready to make predictions on new, unseen data.","metadata":{}},{"cell_type":"code","source":"y_pred=model_dt.predict(x_test)\ny_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code y_pred = model_dt.predict(x_test) uses the trained decision tree model (model_dt) to make predictions on the test data (x_test). The predict() method is a common function in machine learning libraries that predicts the target variable or class labels based on the provided input features.\n\nIn this case, the predict() method is called on the model_dt object with x_test as the parameter. x_test represents the test data or the input features for which we want to make predictions.\n\nBy executing y_pred = model_dt.predict(x_test), the decision tree model uses the learned patterns and rules from the training phase to predict the target variable or class labels for the test data. The predicted values are stored in the y_pred variable.\n\nAfter making predictions, y_pred will contain the predicted class labels or target variable values for the corresponding instances in the x_test dataset. These predicted values can be compared with the actual target variable values (y_test) to evaluate the performance of the model.\n","metadata":{}},{"cell_type":"code","source":"model_dt.score(x_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code model_dt.score(x_test, y_test) calculates the accuracy score of the decision tree model (model_dt) on the test data (x_test and y_test). The score() method is a convenient function provided by many machine learning libraries to evaluate the performance of a model.\n\nIn this case, the score() method is called on the model_dt object with x_test and y_test as the parameters. x_test represents the test features, and y_test represents the corresponding true target variable values or class labels.\n\nThe score() method internally uses the model to make predictions on the x_test data and then compares the predicted values with the true y_test values. It calculates the accuracy of the model by determining the proportion of correctly predicted instances.\n\nThe return value of model_dt.score(x_test, y_test) is the accuracy score, which is a value between 0 and 1. A score of 1 indicates that the model made all predictions correctly, while a score of 0 means that the model did not predict any instances correctly.\n\nBy evaluating the model's accuracy score on the test data, we can assess how well the decision tree model generalizes to unseen examples and how accurately it predicts the target variable values or class labels.","metadata":{}},{"cell_type":"markdown","source":"An accuracy score of 0.7818052594171997 indicates that approximately 78.18% of the instances in the test data were correctly predicted by the model. While it's difficult to provide a definitive judgment without additional context, here are some general guidelines to help interpret the score:\n\nIf this accuracy score is significantly higher than a random or baseline prediction, it can be considered reasonably good. However, the definition of \"reasonably good\" depends on the specific problem and the expectations for accuracy in that domain.\n\nIf there are other models or benchmarks available, it would be useful to compare the accuracy score of model_dt with those models. If the score is comparable or higher, it suggests that the decision tree model is performing well relative to the alternatives.\n\nAdditionally, it is important to consider the problem domain and the associated requirements. Some domains may require high accuracy, while others may prioritize different metrics such as precision, recall, or F1-score. Evaluating the model's performance using multiple metrics can provide a more comprehensive assessment.\n\nIn summary, an accuracy score of 0.7818052594171997 can be considered relatively good depending on the specific context, but it is always recommended to consider additional factors, such as the problem domain and comparison with other models or benchmarks, for a more accurate interpretation.\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, labels=[0,1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The classification_report() function is a utility in the Scikit-learn library that generates a text report showing various evaluation metrics for a classification model. In this case, the classification_report() function is used to print a report for the predicted labels (y_pred) compared to the true labels (y_test).\n\nThe line of code print(classification_report(y_test, y_pred, labels=[0,1])) generates a classification report with specific labels [0, 1]. The report includes several evaluation metrics such as precision, recall, F1-score, and support for each class label.\n\nHere's an explanation of some key metrics in the classification report:\n\nPrecision: Precision measures the proportion of true positive predictions (correctly predicted positive instances) out of all instances predicted as positive. A high precision indicates a low false positive rate.\n\nRecall: Recall, also known as sensitivity or true positive rate, measures the proportion of true positive predictions out of all actual positive instances. A high recall indicates a low false negative rate.\n\nF1-score: The F1-score is the harmonic mean of precision and recall. It provides a balanced measure of both precision and recall.\n\nSupport: Support represents the number of instances in each class. It indicates the number of actual occurrences of each class label in the test data.\n\nBy specifying the labels parameter as [0, 1], the classification report will be generated only for these specific labels.\n\nPrinting the classification report helps assess the performance of the model on each class label individually, providing insights into how well the model is performing for different classes.","metadata":{}},{"cell_type":"markdown","source":"The provided classification report gives a detailed evaluation of the model's performance for two class labels, 0 and 1. Let's analyze the key metrics and what they mean in this context:\n\nFor class label 0:\n\nPrecision: The precision for class 0 is 0.82, indicating that 82% of the instances predicted as class 0 were actually true positives. It has a relatively low false positive rate.\nRecall: The recall for class 0 is 0.89, indicating that 89% of the actual instances of class 0 were correctly identified by the model. It has a relatively low false negative rate.\nF1-score: The F1-score for class 0 is 0.86, which is the harmonic mean of precision and recall. It provides a balanced measure of precision and recall, indicating a reasonably good performance.\nSupport: The support for class 0 is 1023, representing the number of actual occurrences of class 0 in the test data.\nFor class label 1:\n\nPrecision: The precision for class 1 is 0.63, indicating that 63% of the instances predicted as class 1 were actually true positives. It has a moderate false positive rate.\nRecall: The recall for class 1 is 0.49, indicating that 49% of the actual instances of class 1 were correctly identified by the model. It has a relatively high false negative rate.\nF1-score: The F1-score for class 1 is 0.55, indicating a moderate balance between precision and recall.\nSupport: The support for class 1 is 384, representing the number of actual occurrences of class 1 in the test data.\nOverall:\n\nAccuracy: The overall accuracy of the model is 0.78, indicating that approximately 78% of the instances in the test data were predicted correctly by the model.\nMacro avg: The macro average of precision, recall, and F1-score provides the average performance across all classes, giving equal weight to each class. In this case, the macro avg precision, recall, and F1-score are 0.73, 0.69, and 0.70, respectively.\nWeighted avg: The weighted average of precision, recall, and F1-score provides the average performance across all classes, taking into account the support (number of instances) for each class. In this case, the weighted avg precision, recall, and F1-score are 0.77, 0.78, and 0.77, respectively.\nIn summary, the model appears to perform better for class 0, with higher precision, recall, and F1-score. However, it struggles with class 1, with relatively lower values for these metrics. It's important to consider the specific requirements of the problem and the trade-offs between precision and recall when interpreting these results.","metadata":{}},{"cell_type":"markdown","source":"Imbalance in data set so fix that. It has a relatively high false negative rate. ","metadata":{}},{"cell_type":"code","source":"sm = SMOTEENN()\nX_resampled, y_resampled = sm.fit_sample(x,y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code sm = SMOTEENN() initializes an instance of the SMOTEENN class, which is a combination of the Synthetic Minority Over-sampling Technique (SMOTE) and Edited Nearest Neighbors (ENN).\n\nSMOTEENN is a technique commonly used in imbalanced classification problems to address the issue of class imbalance. It combines oversampling of the minority class using SMOTE and undersampling of the majority class using ENN to achieve a balanced dataset.\n\nThe fit_sample() method of SMOTEENN is then called on the input features x and target variable y. This method resamples the data to create a new balanced dataset by applying both SMOTE and ENN techniques.\n\nThe resampled data is returned as X_resampled (the new feature matrix) and y_resampled (the new target variable array), which can be used for training machine learning models on the balanced dataset to mitigate the impact of class imbalance.","metadata":{}},{"cell_type":"code","source":"xr_train,xr_test,yr_train,yr_test=train_test_split(X_resampled, y_resampled,test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code xr_train, xr_test, yr_train, yr_test = train_test_split(X_resampled, y_resampled, test_size=0.2) splits the resampled data (X_resampled and y_resampled) into training and test sets.\n\nThe train_test_split() function is a commonly used utility in machine learning libraries, which divides a dataset into random train and test subsets. In this case, the resampled feature matrix X_resampled and target variable array y_resampled are split into four sets: xr_train (training features), xr_test (test features), yr_train (training target variable), and yr_test (test target variable).\n\nThe test_size parameter is set to 0.2, which means that 20% of the resampled data will be allocated to the test sets, while the remaining 80% will be used for training. The data splitting is done randomly to ensure a representative distribution of instances in both sets.\n\nBy splitting the data into training and test sets, it allows the model to be trained on a portion of the resampled data (xr_train and yr_train) and evaluated on unseen data (xr_test and yr_test) to assess its generalization performance.","metadata":{}},{"cell_type":"code","source":"model_dt_smote=DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=6, min_samples_leaf=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line of code model_dt_smote = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=6, min_samples_leaf=8) creates an instance of the DecisionTreeClassifier class with specific parameters.\n\nHere's an explanation of the parameters used:\n\n* criterion: This parameter specifies the criterion used for splitting the decision tree nodes. In this case, \"gini\" is used, which refers to the Gini impurity criterion. Gini impurity measures the degree of impurity in a node, and the decision tree algorithm aims to minimize it during the tree construction process.\n\n* random_state: This parameter sets the random seed for reproducibility. By setting it to 100, the random number generation for the decision tree will be consistent across different runs, resulting in the same tree structure if the other parameters and data remain unchanged.\n\n* max_depth: This parameter determines the maximum depth or the maximum number of levels in the decision tree. In this case, the maximum depth is set to 6, limiting the tree's complexity and preventing it from growing too deep.\n\n* min_samples_leaf: This parameter sets the minimum number of samples required to be at a leaf node. It controls the minimum size of leaf nodes in the decision tree. In this case, a minimum of 8 samples is required for a node to be considered as a leaf.\n\nBy creating an instance of DecisionTreeClassifier with these parameters, model_dt_smote is initialized as a decision tree classifier that will use the Gini criterion for splitting nodes, have a maximum depth of 6, and a minimum of 8 samples at each leaf node. This model will be trained and evaluated using the resampled data obtained through the SMOTEENN technique.","metadata":{}},{"cell_type":"code","source":"model_dt_smote.fit(xr_train,yr_train)\nyr_predict = model_dt_smote.predict(xr_test)\nmodel_score_r = model_dt_smote.score(xr_test, yr_test)\nprint(model_score_r)\nprint(metrics.classification_report(yr_test, yr_predict))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code provided trains and evaluates the model_dt_smote decision tree classifier on the resampled training data and prints the model's score and classification report based on the predictions made on the resampled test data. The fit() method is called on model_dt_smote to train the decision tree classifier using the resampled training data (xr_train as features and yr_train as target variables). This step involves constructing the decision tree based on the provided data. The predict() method is used to make predictions on the resampled test data (xr_test) using the trained model_dt_smote. The predicted target variable values are stored in the yr_predict variable.The score() method is called on model_dt_smote to calculate the accuracy score of the model on the resampled test data (xr_test and yr_test). The accuracy score represents the proportion of correctly predicted instances.This line prints the accuracy score of the model (model_score_r).The classification_report() function from the metrics module is used to generate a text report that includes various evaluation metrics for the predictions made by model_dt_smote on the resampled test data (yr_test as true labels and yr_predict as predicted labels). This report provides detailed information on metrics such as precision, recall, F1-score, and support for each class.\n\nBy printing the accuracy score and classification report, you can assess the performance of the decision tree classifier (model_dt_smote) on the resampled test data and gain insights into its predictive capabilities for each class label.\n\n","metadata":{}},{"cell_type":"markdown","source":"The provided output includes the accuracy score and classification report for the model_dt_smote decision tree classifier on the resampled test data. Let's analyze the results:\n\nAccuracy Score: The accuracy score is 0.934412265758092, which means that approximately 93.44% of the instances in the resampled test data were correctly predicted by the model. This indicates a high level of accuracy in the predictions.\n\nClassification Report:\n\nFor class label 0:\n\nPrecision: The precision for class 0 is 0.97, indicating that 97% of the instances predicted as class 0 were actually true positives. It has a relatively low false positive rate.\nRecall: The recall for class 0 is 0.88, indicating that 88% of the actual instances of class 0 were correctly identified by the model. It has a relatively low false negative rate.\nF1-score: The F1-score for class 0 is 0.93, which is the harmonic mean of precision and recall. It provides a balanced measure of precision and recall, indicating a good performance.\nSupport: The support for class 0 is 540, representing the number of actual occurrences of class 0 in the resampled test data.\nFor class label 1:\n\nPrecision: The precision for class 1 is 0.91, indicating that 91% of the instances predicted as class 1 were actually true positives. It has a relatively low false positive rate.\nRecall: The recall for class 1 is 0.98, indicating that 98% of the actual instances of class 1 were correctly identified by the model. It has a relatively low false negative rate.\nF1-score: The F1-score for class 1 is 0.94, indicating a balanced measure of precision and recall.\nSupport: The support for class 1 is 634, representing the number of actual occurrences of class 1 in the resampled test data.\nOverall:\n\nThe weighted average precision, recall, and F1-score are 0.94, 0.93, and 0.93, respectively. The weighted average takes into account the support (number of instances) for each class, providing an overall measure of performance that considers both class imbalances.\nThe macro average precision, recall, and F1-score are 0.94, 0.93, and 0.93, respectively. The macro average calculates the average performance across all classes, giving equal weight to each class.\nThe accuracy, precision, recall, and F1-score values indicate that the model performs well for both class labels, with high values across the metrics.\nIn summary, the model_dt_smote decision tree classifier shows strong performance on the resampled test data, achieving high accuracy and demonstrating good precision, recall, and F1-score for both class labels. These results suggest that the model is effective in making predictions on the resampled data and accurately classifying instances into their respective classes.","metadata":{}},{"cell_type":"markdown","source":"For example, if you are working on a churn prediction problem, Class 0 could represent customers who do not churn (stay with the service), and Class 1 could represent customers who churn (cancel their subscription). In this case, the confusion matrix and classification report would provide insights into how well the model is performing in predicting customers who do not churn (Class 0) and customers who do churn (Class 1).","metadata":{}},{"cell_type":"code","source":"print(metrics.confusion_matrix(yr_test, yr_predict))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix is a 2x2 matrix representing the two class labels (0 and 1). Let's break it down:\n\nTrue Negatives (TN): The number of instances that were correctly predicted as class 0. In this case, there are 476 true negatives, which means 476 instances that were actually class 0 were correctly classified as class 0.\n\nFalse Positives (FP): The number of instances that were incorrectly predicted as class 1 (false alarms or type I errors). In this case, there are 64 false positives, which means 64 instances that were actually class 0 were wrongly classified as class 1.\n\nFalse Negatives (FN): The number of instances that were incorrectly predicted as class 0 (misses or type II errors). In this case, there are 14 false negatives, which means 14 instances that were actually class 1 were wrongly classified as class 0.\n\nTrue Positives (TP): The number of instances that were correctly predicted as class 1. In this case, there are 620 true positives, which means 620 instances that were actually class 1 were correctly classified as class 1.\n\nThe confusion matrix provides important information about the performance of the model, allowing for a more detailed analysis of the model's ability to correctly classify instances into their respective classes.","metadata":{}},{"cell_type":"markdown","source":"The code print(metrics.confusion_matrix(yr_test, yr_predict)) generates the confusion matrix for the predictions made by the model_dt_smote decision tree classifier on the resampled test data. The confusion matrix provides a tabular representation of the model's performance by counting the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).","metadata":{}},{"cell_type":"markdown","source":"###### Now we can see quite better results, i.e. Accuracy: 92 %, and a very good recall, precision & f1 score for minority class.\n\n###### Let's try with some other classifier.","metadata":{}},{"cell_type":"markdown","source":"#### Random Forest Classifier","metadata":{}},{"cell_type":"markdown","source":"Random Forest Classifier and Decision Tree are both popular machine learning algorithms used for classification tasks, but they have some key differences. Here's a comparison between Random Forest Classifier and Decision Tree:\n\nDecision Tree:\n\nA Decision Tree is a simple and interpretable algorithm that predicts the target variable by recursively partitioning the feature space into smaller regions based on the feature values.\nIt makes decisions based on a series of binary splits at each node of the tree, dividing the data based on the features that provide the most information gain or the best split criterion (e.g., Gini impurity or information gain).\nDecision Trees tend to be prone to overfitting, meaning they can create complex trees that fit the training data too closely and may not generalize well to unseen data.\nRandom Forest Classifier:\n\nRandom Forest is an ensemble learning method that combines multiple Decision Trees to make predictions. It builds an ensemble of Decision Trees and aggregates their predictions to make the final prediction.\nEach Decision Tree in the Random Forest is trained on a random subset of the training data (sampling with replacement) and a random subset of the features.\nRandom Forest reduces the overfitting problem of individual Decision Trees by averaging the predictions of multiple trees, which helps to improve the model's generalization performance.\nIt can handle high-dimensional data and capture complex interactions between features.\nAdvantages of Decision Tree:\n\nDecision Trees are easy to understand and interpret, providing human-readable rules that explain the decision-making process.\nThey can handle both numerical and categorical features without requiring extensive data preprocessing.\nDecision Trees can capture non-linear relationships between features and the target variable.\nAdvantages of Random Forest Classifier:\n\nRandom Forest combines the predictions of multiple Decision Trees, leading to more robust and accurate predictions.\nIt reduces the risk of overfitting by introducing randomness in the model training process.\nRandom Forest can handle large datasets with high dimensionality and noisy data.\nIn summary, Decision Trees are simple and interpretable but can be prone to overfitting, while Random Forest Classifier is an ensemble of Decision Trees that provides better generalization performance and handles complex datasets. However, Random Forest may be more computationally expensive and less interpretable compared to a single Decision Tree. The choice between the two algorithms depends on the specific requirements of the problem and the trade-offs between interpretability, accuracy, and computational resources.","metadata":{}},{"cell_type":"markdown","source":"In general, when it comes to predicting churn rate, Random Forest Classifier tends to perform better than a single Decision Tree. Here's why:\n\nHandling complex relationships: Churn prediction involves analyzing various factors and their interactions that contribute to customer churn. Random Forest Classifier can handle complex relationships between features by combining multiple Decision Trees. It captures different patterns and interactions present in the data, leading to improved predictive performance.\n\nHandling high-dimensional data: Churn prediction often involves working with datasets that have a high number of features or attributes. Random Forest Classifier can effectively handle high-dimensional data without overfitting. It selects a random subset of features for each tree, ensuring that different subsets of features are considered, reducing the risk of spurious correlations and improving generalization.\n\nDealing with class imbalance: Churn prediction tasks often suffer from class imbalance, where the number of churned customers (positive class) is significantly smaller than the number of non-churned customers (negative class). Random Forest Classifier can handle class imbalance better than a single Decision Tree. By using bootstrapping and random feature selection, it can mitigate the impact of class imbalance and provide more balanced predictions.\n\nRobustness and generalization: Random Forest Classifier reduces the risk of overfitting by aggregating predictions from multiple Decision Trees. It combines the strengths of individual trees and reduces the impact of noise or outliers in the data. This leads to more robust and accurate predictions, improving the model's ability to generalize well to unseen data.\n\nOverall, due to its ability to handle complex relationships, high-dimensional data, class imbalance, and improve generalization, Random Forest Classifier is generally considered a better choice for churn rate prediction compared to a single Decision Tree. However, it's important to note that the performance of the algorithm can still depend on the specific characteristics of the dataset and the tuning of hyperparameters. It's always recommended to experiment and evaluate different algorithms to find the best solution for a particular churn prediction problem.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet from sklearn.ensemble import RandomForestClassifier imports the RandomForestClassifier class from the sklearn.ensemble module in scikit-learn.\n\nEnsemble learning refers to the technique of combining multiple machine learning models to make predictions. Random Forest is an ensemble learning method that combines multiple decision trees to create a more robust and accurate model.\n\nThe RandomForestClassifier class in scikit-learn is an implementation of the Random Forest algorithm specifically designed for classification tasks. It inherits the properties and methods from the base ClassifierMixin class in scikit-learn.\n\nBy importing RandomForestClassifier, you gain access to various functionalities and parameters to create, train, and use a Random Forest Classifier in your code. You can instantiate an instance of the RandomForestClassifier class and configure its parameters to customize the behavior of the classifier.\n\nFor example, you can set parameters such as n_estimators (the number of decision trees in the Random Forest), max_depth (the maximum depth of each decision tree), min_samples_leaf (the minimum number of samples required to be at a leaf node), and many more. These parameters allow you to control the complexity, generalization ability, and performance of the Random Forest Classifier.\n\nOnce you have created an instance of the RandomForestClassifier, you can use it to train the model on labeled training data, make predictions on new unseen data, and evaluate the performance of the classifier using various evaluation metrics.\n\nIn summary, importing RandomForestClassifier from sklearn.ensemble provides you with the necessary tools and functionality to create and use a Random Forest Classifier for classification tasks in scikit-learn.","metadata":{}},{"cell_type":"code","source":"model_rf=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The RandomForestClassifier class from the scikit-learn library, which is a popular library for machine learning in Python. The RandomForestClassifier is an ensemble learning method that constructs multiple decision trees and combines their predictions to make a final classification.\n\nLet's break down the parameters used when creating the RandomForestClassifier instance:\n\nn_estimators=100: This parameter specifies the number of decision trees (or estimators) to be created in the random forest. In this case, the random forest will consist of 100 decision trees.\n\ncriterion='gini': The criterion parameter defines the function to measure the quality of a split in each decision tree. 'Gini' is a measure of impurity commonly used in decision trees and random forests. It determines how well a split separates different classes in the training data.\n\nrandom_state=100: The random_state parameter sets the random seed for reproducibility. By specifying a specific value (in this case, 100), you ensure that the random forest will produce the same results if you run the code again with the same parameters.\n\nmax_depth=6: This parameter sets the maximum depth of each decision tree in the random forest. The depth of a tree represents the number of levels or splits it can make. By setting it to 6, you limit the depth of each tree to 6 levels, which can help control the complexity and overfitting of the model.\n\nmin_samples_leaf=8: The min_samples_leaf parameter determines the minimum number of samples required to be at a leaf node of a decision tree. Setting it to 8 means that a leaf node must have at least 8 training samples to be considered valid. This parameter helps control the tree's tendency to overfit the training data.\n\nOverall, this code initializes a RandomForestClassifier model with 100 decision trees, uses the Gini impurity criterion for splitting, sets a random seed for reproducibility, limits the maximum depth of each tree to 6, and requires at least 8 samples at leaf nodes. This model can be used for classification tasks by fitting it to a labeled training dataset and then using it to make predictions on new, unseen data.","metadata":{}},{"cell_type":"markdown","source":"Let's go over the concepts behind the parameters criterion, random_state, max_depth, and min_samples_leaf in the context of the RandomForestClassifier:\n\ncriterion: The criterion parameter is used to measure the quality of a split in each decision tree of the random forest. In the case of the RandomForestClassifier, two common criteria are available: \"gini\" and \"entropy\".\n\nGini impurity (criterion='gini'): Gini impurity is a measure of impurity or disorder in a set of samples. It quantifies how well a split separates different classes in the training data. A lower Gini impurity indicates a more homogeneous subset of samples with respect to the target variable.\n\nEntropy (criterion='entropy'): Entropy is another measure of impurity that calculates the information gain or reduction in entropy achieved by a split. Similar to Gini impurity, a lower entropy value indicates a more homogeneous subset of samples.\n\nBoth criteria work well in practice, and the choice between them often comes down to personal preference or specific problem requirements.\n\nrandom_state: The random_state parameter is used to initialize the random number generator. It serves two purposes:\n\nReproducibility: By setting random_state to a specific value (e.g., random_state = 100), you ensure that the random forest model's behavior remains consistent across different runs. This allows you to reproduce the same results, which can be useful for debugging, sharing code, or achieving consistent performance evaluations.\n\nRandomness Control: Random forests use randomness during training, such as randomly selecting subsets of features and samples for building each tree. By setting random_state, you fix the random seed, making the training process deterministic. This allows you to control and compare different models by keeping other factors constant.\n\nmax_depth: The max_depth parameter specifies the maximum depth or levels of each decision tree in the random forest. A decision tree grows by recursively splitting the data based on feature values. A higher max_depth allows the trees to capture more complex relationships in the data, but it also increases the risk of overfitting. Setting a lower max_depth limits the depth of each tree, preventing them from becoming too complex. It can help control model complexity, reduce training time, and improve generalization on unseen data.\n\nmin_samples_leaf: The min_samples_leaf parameter sets the minimum number of samples required to be at a leaf (terminal) node of a decision tree. A leaf node represents a final prediction or class assignment. By specifying min_samples_leaf, you ensure that each leaf node contains at least the specified number of samples. This parameter helps prevent the tree from overfitting the training data by avoiding excessively specific and intricate splits that might be outliers or noise. A higher min_samples_leaf value can lead to simpler and more robust decision trees.\n\nThese parameters allow you to customize the behavior of the random forest model based on your specific needs and the characteristics of your dataset. Adjusting them appropriately can impact the model's performance, interpretability, and training time.","metadata":{}},{"cell_type":"markdown","source":"\nGini impurity is a measure of impurity or disorder used in decision tree algorithms and random forests. It quantifies the degree of impurity in a set of samples or data points based on the distribution of class labels.\n\nIn the context of classification tasks, Gini impurity measures the probability of misclassifying a randomly chosen sample in a dataset. A Gini impurity of 0 indicates a completely pure set where all samples belong to the same class, while a Gini impurity of 1 indicates maximum impurity or an equal distribution of samples across all classes.\n\nMathematically, the Gini impurity for a set S is calculated as:\n\nGini(S) = 1 - Σ (p(i)^2)\n\nwhere p(i) is the probability of a sample being classified as class i within the set S. The summation is performed over all the classes in the dataset.\n\nIntuitively, a lower Gini impurity value suggests that the samples in the set are predominantly of the same class, making it more \"pure.\" On the other hand, a higher Gini impurity indicates a higher degree of mixing of different classes within the set, signifying a higher level of impurity or disorder.\n\nIn decision tree algorithms, Gini impurity is commonly used as a criterion to evaluate the quality of a split. When constructing a decision tree, the algorithm aims to find the splits that minimize the Gini impurity in the resulting child nodes, as this leads to more homogeneous subsets of samples with respect to the target variable.\n\nIn the case of random forests, each decision tree within the ensemble is built using different subsets of the data and features. The individual trees' predictions are then combined to make a final prediction, often using majority voting. Gini impurity is used as one of the criteria to determine the quality of splits in each tree and guide the construction of the random forest model.","metadata":{}},{"cell_type":"code","source":"model_rf.fit(x_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_rf.fit(x_train, y_train) is used to train (fit) the RandomForestClassifier model (model_rf) on the training data (x_train and y_train).\n\nHere's a breakdown of the code:\n\nmodel_rf: This is the instance of the RandomForestClassifier that you created earlier using the specified parameters.\n\nfit(): This is a method in scikit-learn's machine learning models that is used to train the model on the provided training data.\n\nx_train: This variable represents the input features (also known as predictors or independent variables) of the training data. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a training sample and each column represents a feature.\n\ny_train: This variable represents the target variable (also known as the dependent variable or labels) of the training data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the corresponding target values for each training sample.\n\nWhen you execute model_rf.fit(x_train, y_train), the random forest model will analyze the training data and create a collection of decision trees based on the specified parameters. Each tree will be trained on a random subset of the training data, making predictions based on the selected features. The trees will work together to produce a final prediction by either voting (classification) or averaging (regression) their individual predictions.\n\nThe fit() method modifies the model_rf object in place, updating its internal state to reflect the learned patterns in the training data. Once the model is trained, you can use it to make predictions on new, unseen data.","metadata":{}},{"cell_type":"code","source":"y_pred=model_rf.predict(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code y_pred = model_rf.predict(x_test) is used to make predictions on new, unseen data using the trained RandomForestClassifier model (model_rf).\n\nHere's a breakdown of the code:\n\ny_pred: This variable represents the predicted output or labels for the given test data. It will store the predicted class labels or values based on the input features (x_test).\n\nmodel_rf: This is the trained instance of the RandomForestClassifier model that you previously fitted on the training data.\n\npredict(): This is a method in scikit-learn's machine learning models that is used to make predictions on new data. In this case, the predict() method is applied to the model_rf object.\n\nx_test: This variable represents the input features of the test data. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a test sample and each column represents a feature.\n\nWhen you execute y_pred = model_rf.predict(x_test), the random forest model uses the trained decision trees to predict the target variable (class labels or values) for the given test data (x_test). The model applies each decision tree to the test samples and aggregates the individual predictions to produce the final predictions.\n\nThe resulting y_pred array or object will contain the predicted labels or values corresponding to the provided test samples. These predictions can be used for evaluation, further analysis, or any other task that requires the model's output on unseen data.","metadata":{}},{"cell_type":"code","source":"model_rf.score(x_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_rf.score(x_test, y_test) is used to calculate the accuracy score of the RandomForestClassifier model (model_rf) on the provided test data (x_test and y_test).\n\nHere's a breakdown of the code:\n\nmodel_rf: This is the trained instance of the RandomForestClassifier model that you previously fitted on the training data.\n\nscore(): This is a method in scikit-learn's machine learning models that calculates the accuracy of the model's predictions. In the case of classification models, like RandomForestClassifier, the score() method computes the accuracy score.\n\nx_test: This variable represents the input features of the test data. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a test sample and each column represents a feature.\n\ny_test: This variable represents the true labels or target values for the test data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the corresponding true labels or values for each test sample.\n\nWhen you execute model_rf.score(x_test, y_test), the random forest model uses the trained decision trees to predict the target variable (class labels or values) for the given test data (x_test). It then compares the predicted labels with the true labels (y_test) and calculates the accuracy score.\n\nThe accuracy score is a measure of how well the model's predictions match the true labels. It is defined as the fraction of correctly classified samples (or instances) out of the total number of samples. The score ranges from 0 to 1, where 1 represents a perfect match between the model's predictions and the true labels, while 0 indicates no correct predictions.\n\nThe returned value from model_rf.score(x_test, y_test) will be the accuracy score of the model on the provided test data. This score provides an indication of the model's performance in terms of classification accuracy.","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, labels=[0,1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code print(classification_report(y_test, y_pred, labels=[0, 1])) is used to print a classification report that includes various evaluation metrics for the predicted labels (y_pred) compared to the true labels (y_test), specifically for the classes 0 and 1.\n\nHere's a breakdown of the code:\n\nclassification_report(): This is a function from the scikit-learn library that generates a text report displaying various classification metrics. It takes the true labels (y_test) and the predicted labels (y_pred) as input.\n\ny_test: This variable represents the true labels or target values for the test data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the corresponding true labels for each test sample.\n\ny_pred: This variable represents the predicted labels for the test data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the predicted labels produced by the model for each test sample.\n\nlabels=[0, 1]: This parameter specifies the labels for which the classification report will be generated. In this case, it restricts the report to the classes 0 and 1, providing metrics specific to these two classes.\n\nWhen you execute print(classification_report(y_test, y_pred, labels=[0, 1])), it will generate a classification report containing several evaluation metrics, such as precision, recall, F1-score, and support, for each specified class (0 and 1). These metrics assess the model's performance in terms of classifying samples into the respective classes.\n\nThe precision measures the proportion of correctly predicted positive samples out of all samples predicted as positive. The recall, also known as sensitivity or true positive rate, measures the proportion of correctly predicted positive samples out of all actual positive samples. The F1-score is the harmonic mean of precision and recall, providing a balanced measure between the two. The support represents the number of samples for each class in the test set.\n\nBy printing the classification report, you can gain insights into how well the model performs for the specific classes of interest, assessing its precision, recall, and overall effectiveness in classifying samples belonging to those classes.","metadata":{}},{"cell_type":"code","source":"sm = SMOTEENN()\nX_resampled1, y_resampled1 = sm.fit_sample(x,y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code sm = SMOTEENN() creates an instance of the SMOTEENN (SMOTE + Edited Nearest Neighbors) algorithm, which is a combination of the Synthetic Minority Over-sampling Technique (SMOTE) and Edited Nearest Neighbors (ENN) algorithm.\n\nHere's a breakdown of the code:\n\nSMOTEENN(): This is a class from the imbalanced-learn library (imblearn) that combines the SMOTE and ENN algorithms for addressing imbalanced classification problems. SMOTE is used to oversample the minority class by generating synthetic samples, and ENN is used to clean the resulting dataset by removing noisy samples and samples that are misclassified by the k-nearest neighbors classifier.\n\nsm: This variable represents the instance of the SMOTEENN algorithm that you created.\n\nX_resampled1, y_resampled1: These variables store the resampled version of the input features (x) and the corresponding target variable (y), respectively, after applying the SMOTEENN algorithm.\n\nfit_sample(): This is a method of the SMOTEENN class that performs the resampling process. It takes the input features (x) and the target variable (y) as input and returns the resampled versions (X_resampled1 and y_resampled1) with balanced class distribution.\n\nWhen you execute X_resampled1, y_resampled1 = sm.fit_sample(x, y), the SMOTEENN algorithm is applied to the input data (x and y). The algorithm first applies the SMOTE technique to oversample the minority class, generating synthetic samples to balance the class distribution. Then, it applies the ENN algorithm to clean the resulting dataset by removing noisy samples and samples that are misclassified by the k-nearest neighbors classifier.\n\nThe resampled versions (X_resampled1 and y_resampled1) will have a balanced class distribution, making it suitable for training a machine learning model in scenarios where class imbalance is a concern.\n\nNote that the code assumes x represents the input features as a 2-dimensional array-like object, and y represents the target variable as a 1-dimensional array-like object.","metadata":{}},{"cell_type":"code","source":"xr_train1,xr_test1,yr_train1,yr_test1=train_test_split(X_resampled1, y_resampled1,test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code xr_train1, xr_test1, yr_train1, yr_test1 = train_test_split(X_resampled1, y_resampled1, test_size=0.2) is used to split the resampled data (X_resampled1 and y_resampled1) into training and testing sets for model evaluation.\n\nHere's a breakdown of the code:\n\nX_resampled1: This variable represents the resampled input features obtained after applying the SMOTEENN algorithm.\n\ny_resampled1: This variable represents the corresponding resampled target variable obtained after applying the SMOTEENN algorithm.\n\ntrain_test_split(): This is a function from the scikit-learn library that allows you to randomly split the data into training and testing sets. It takes the input features (X_resampled1) and the target variable (y_resampled1) as input.\n\nxr_train1: This variable represents the training set of input features (X_resampled1) after the split.\n\nxr_test1: This variable represents the testing set of input features (X_resampled1) after the split.\n\nyr_train1: This variable represents the training set of the target variable (y_resampled1) after the split.\n\nyr_test1: This variable represents the testing set of the target variable (y_resampled1) after the split.\n\ntest_size=0.2: This parameter specifies the proportion of the data that should be allocated for testing. In this case, 20% of the data will be assigned to the testing set, while the remaining 80% will be used for training.\n\nWhen you execute xr_train1, xr_test1, yr_train1, yr_test1 = train_test_split(X_resampled1, y_resampled1, test_size=0.2), the resampled data (X_resampled1 and y_resampled1) is randomly split into two sets: one for training and one for testing. The training set (xr_train1 and yr_train1) will be used to train a machine learning model, while the testing set (xr_test1 and yr_test1) will be used to evaluate the trained model's performance.\n\nBy splitting the data into training and testing sets, you can assess how well the model generalizes to unseen data. The testing set, which was not used during model training, provides an unbiased evaluation of the model's performance on new, unseen samples.","metadata":{}},{"cell_type":"code","source":"model_rf_smote=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_rf_smote = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8) creates an instance of the RandomForestClassifier model with specific parameter settings.\n\nHere's a breakdown of the code:\n\nmodel_rf_smote: This variable represents the instance of the RandomForestClassifier model with the specified parameter settings.\n\nRandomForestClassifier: This is a class from the scikit-learn library that implements the random forest algorithm for classification. It is an ensemble learning method that combines multiple decision trees to make predictions.\n\nn_estimators=100: This parameter specifies the number of decision trees to be used in the random forest ensemble. In this case, the ensemble will consist of 100 decision trees.\n\ncriterion='gini': This parameter determines the criterion used to measure the quality of a split in each decision tree. In this case, the Gini impurity criterion is used. The Gini impurity measures the degree of impurity or disorder in a set of samples.\n\nrandom_state=100: This parameter sets the random seed to ensure reproducibility. By setting a specific random seed, the random forest algorithm will produce the same results when run multiple times with the same data and parameters.\n\nmax_depth=6: This parameter sets the maximum depth allowed for each decision tree in the random forest. It limits the number of levels in the tree, controlling the complexity and potential overfitting of the model.\n\nmin_samples_leaf=8: This parameter specifies the minimum number of samples required to be at a leaf node of the decision trees. It prevents the trees from creating leaf nodes with too few samples, which can help regularize the model and avoid overfitting.\n\nBy creating model_rf_smote with the specified parameter settings, you have an instance of the RandomForestClassifier model ready to be trained on the resampled data obtained through the SMOTEENN technique.","metadata":{}},{"cell_type":"code","source":"model_rf_smote.fit(xr_train1,yr_train1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_rf_smote.fit(xr_train1, yr_train1) is used to train the RandomForestClassifier model (model_rf_smote) on the resampled training data (xr_train1 and yr_train1) obtained through the SMOTEENN technique.\n\nHere's a breakdown of the code:\n\nmodel_rf_smote: This variable represents the instance of the RandomForestClassifier model that you previously created.\n\nfit(): This method is used in scikit-learn's machine learning models to train the model on the provided data. It takes the input features (xr_train1) and the corresponding target variable (yr_train1) as input.\n\nxr_train1: This variable represents the resampled training set of input features obtained through the SMOTEENN technique. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a training sample and each column represents a feature.\n\nyr_train1: This variable represents the resampled training set of the target variable obtained through the SMOTEENN technique. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the corresponding target values for each training sample.\n\nWhen you execute model_rf_smote.fit(xr_train1, yr_train1), the RandomForestClassifier model is trained using the resampled training data. The model learns from the input features and their corresponding target values, building an ensemble of decision trees that collectively make predictions.\n\nDuring the training process, the model adjusts the parameters of the decision trees to minimize the difference between the predicted labels and the true labels in the training data. The random forest algorithm combines the predictions of multiple decision trees to make more accurate and robust predictions.\n\nAfter executing this code, model_rf_smote will be trained on the resampled training data and ready to be used for making predictions on new, unseen data.","metadata":{}},{"cell_type":"code","source":"yr_predict1 = model_rf_smote.predict(xr_test1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code yr_predict1 = model_rf_smote.predict(xr_test1) is used to make predictions using the trained RandomForestClassifier model (model_rf_smote) on the resampled testing data (xr_test1).\n\nHere's a breakdown of the code:\n\nyr_predict1: This variable represents the predicted target values obtained from applying the trained model to the resampled testing data.\n\npredict(): This method is used in scikit-learn's machine learning models to make predictions on new, unseen data. It takes the input features (xr_test1) as input and returns the predicted target values.\n\nxr_test1: This variable represents the resampled testing set of input features obtained through the SMOTEENN technique. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a testing sample and each column represents a feature.\n\nWhen you execute yr_predict1 = model_rf_smote.predict(xr_test1), the trained RandomForestClassifier model is used to predict the target values for the resampled testing data. The model applies the ensemble of decision trees to the input features and generates the predicted target values.\n\nThe predicted target values are assigned to the variable yr_predict1, which can be further used for evaluating the performance of the model, comparing it with the true target values (yr_test1), or generating various evaluation metrics.\n\nIt's important to note that the xr_test1 data used for prediction should correspond to the same feature space as the xr_train1 data used for training the model.","metadata":{}},{"cell_type":"code","source":"model_score_r1 = model_rf_smote.score(xr_test1, yr_test1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_score_r1 = model_rf_smote.score(xr_test1, yr_test1) is used to calculate the accuracy of the trained RandomForestClassifier model (model_rf_smote) on the resampled testing data (xr_test1 and yr_test1).\n\nHere's a breakdown of the code:\n\nmodel_score_r1: This variable stores the accuracy score obtained by the model on the resampled testing data.\n\nscore(): This method is used in scikit-learn's machine learning models to calculate the accuracy of the model on the provided data. It takes the input features (xr_test1) and the corresponding true target values (yr_test1) as input and returns the accuracy score.\n\nxr_test1: This variable represents the resampled testing set of input features obtained through the SMOTEENN technique. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a testing sample and each column represents a feature.\n\nyr_test1: This variable represents the true target values for the resampled testing data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the corresponding true target values for each testing sample.\n\nWhen you execute model_score_r1 = model_rf_smote.score(xr_test1, yr_test1), the trained RandomForestClassifier model predicts the target values for the resampled testing data (xr_test1) and compares them with the true target values (yr_test1). It then calculates the accuracy of the model by computing the proportion of correct predictions.\n\nThe accuracy score, representing the model's performance on the resampled testing data, is assigned to the variable model_score_r1. The score ranges from 0 to 1, with a value of 1 indicating perfect accuracy, i.e., all predictions match the true labels.\n\nThe accuracy score provides a measure of how well the trained model generalizes to unseen data. However, it is important to consider other evaluation metrics and assess the model's performance from different perspectives to obtain a comprehensive understanding of its effectiveness.","metadata":{}},{"cell_type":"code","source":"print(model_score_r1)\nprint(metrics.classification_report(yr_test1, yr_predict1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The print() function is used to display the information on the console. The accuracy score is printed using the model_score_r1 variable, which should contain the accuracy score calculated by the score() method of the model. The classification_report() function from the metrics module is used to generate a text-based report that includes precision, recall, F1-score, and support for each class based on the true target values (yr_test1) and the predicted target values (yr_predict1).\n\nBy executing this code, you will see the accuracy score displayed on one line and the classification report printed below it, providing more detailed information about the performance of the model on each class.","metadata":{}},{"cell_type":"code","source":"print(metrics.confusion_matrix(yr_test1, yr_predict1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The print() function is used to display the information on the console. The confusion_matrix() function from the metrics module is used to calculate and print the confusion matrix based on the true target values (yr_test1) and the predicted target values (yr_predict1).\n\nBy executing this code, you will see the confusion matrix printed, which provides a tabular representation of the counts of true positive, false positive, true negative, and false negative predictions for each class. The rows of the matrix represent the true classes, while the columns represent the predicted classes.","metadata":{}},{"cell_type":"markdown","source":"With RF Classifier, also we are able to get quite good results, infact better than Decision Tree.\n\nWe can now further go ahead and create multiple classifiers to see how the model performance is, but that's not covered here, so you can do it by yourself ","metadata":{}},{"cell_type":"markdown","source":"#### Performing PCA","metadata":{}},{"cell_type":"code","source":"# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(0.9)\nxr_train_pca = pca.fit_transform(xr_train1)\nxr_test_pca = pca.transform(xr_test1)\nexplained_variance = pca.explained_variance_ratio_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided applies Principal Component Analysis (PCA) to the resampled training and testing data. PCA is a dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional representation while preserving the most important information.\n\nHere's a breakdown of the code:\n\nfrom sklearn.decomposition import PCA: This line imports the PCA class from the scikit-learn library, which provides the functionality for performing PCA.\n\npca = PCA(0.9): This line creates an instance of the PCA class with the parameter 0.9. Here, 0.9 indicates that we want to retain 90% of the variance in the data after the dimensionality reduction. The PCA algorithm will automatically determine the number of principal components needed to achieve this variance threshold.\n\nxr_train_pca = pca.fit_transform(xr_train1): This line applies PCA to the resampled training data (xr_train1). The fit_transform() method computes the principal components and performs the dimensionality reduction on the training data. It returns the transformed training data, xr_train_pca, where the number of columns (dimensions) is reduced based on the chosen variance threshold.\n\nxr_test_pca = pca.transform(xr_test1): This line applies the previously fitted PCA model to the resampled testing data (xr_test1). The transform() method performs the dimensionality reduction on the testing data using the same principal components obtained from the training data. It returns the transformed testing data, xr_test_pca, with the same reduced number of dimensions.\n\nexplained_variance = pca.explained_variance_ratio_: This line calculates the ratio of explained variance for each principal component in the PCA transformation. The explained_variance_ratio_ attribute of the PCA object returns an array where each element represents the proportion of the total variance explained by the corresponding principal component.\n\nAfter executing this code, you will have the transformed training data (xr_train_pca), transformed testing data (xr_test_pca), and the explained variance ratios (explained_variance) for each principal component. These reduced-dimensional datasets can be used for training and evaluating models while capturing a significant amount of the original data's variability.","metadata":{}},{"cell_type":"markdown","source":"PCA stands for Principal Component Analysis. It is a widely used dimensionality reduction technique in machine learning and data analysis. PCA transforms a high-dimensional dataset into a lower-dimensional representation while preserving the most important patterns or features of the original data.\n\nThe main goal of PCA is to find a set of new uncorrelated variables called principal components that capture the maximum amount of variance in the data. Each principal component is a linear combination of the original features, and they are ordered in terms of the amount of variance they explain. The first principal component captures the most variance, followed by the second, third, and so on.\n\nPCA achieves dimensionality reduction by discarding the least important principal components, which have lower variances and thus contain less information. The retained principal components provide a compressed representation of the original data, reducing the dimensionality while still retaining as much of the important information as possible.\n\nThe reduced-dimensional data obtained through PCA can offer several benefits, including:\n\nDimensionality reduction: PCA allows for reducing the number of features or variables in a dataset, which can be beneficial for visualization, computational efficiency, and dealing with the curse of dimensionality.\n\nData visualization: PCA can be used to project high-dimensional data onto lower-dimensional spaces, such as 2D or 3D, to facilitate visualization and gain insights into the structure and relationships within the data.\n\nNoise reduction: By discarding the least important principal components, which may correspond to noise or irrelevant features, PCA can help reduce the impact of noise in the data and improve the signal-to-noise ratio.\n\nFeature extraction: PCA can extract the most important patterns or features from the original data, providing a compact representation that can be used as input for further analysis or modeling tasks.\n\nIt's important to note that PCA is an unsupervised technique, meaning it does not consider the class labels or target variable during the transformation. It solely focuses on capturing the intrinsic structure and variability of the data based on the feature values.\n\nIn Python, scikit-learn provides a convenient implementation of PCA through the PCA class in the sklearn.decomposition module, allowing for easy application of PCA to datasets.","metadata":{}},{"cell_type":"code","source":"model=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet model=RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8) creates an instance of the RandomForestClassifier class from scikit-learn's ensemble module.\n\nHere's a breakdown of the parameters used in the RandomForestClassifier:\n\nn_estimators: This parameter specifies the number of decision trees to be created in the random forest. In this case, n_estimators=100 means that the random forest will consist of 100 decision trees.\n\ncriterion: This parameter determines the quality of a split in each decision tree. In this case, criterion='gini' specifies that the Gini impurity is used as the criterion to measure the quality of the splits.\n\nrandom_state: This parameter is used to set the random seed for reproducibility. It ensures that the same random sequence is generated each time the code is run, which allows for obtaining consistent results. In this case, random_state=100 sets the random seed to 100.\n\nmax_depth: This parameter controls the maximum depth of each decision tree in the random forest. It limits the number of levels in the tree. In this case, max_depth=6 specifies that each decision tree can have a maximum depth of 6 levels.\n\nmin_samples_leaf: This parameter sets the minimum number of samples required to be at a leaf node. It defines the minimum number of samples that should be present in each leaf node of the decision tree. In this case, min_samples_leaf=8 specifies that each leaf node must have at least 8 samples.\n\nBy instantiating the RandomForestClassifier class with these parameters, you have created a random forest model with 100 decision trees, using the Gini impurity criterion for splitting, a fixed random seed of 100 for reproducibility, a maximum depth of 6 for each tree, and a minimum of 8 samples per leaf node.\n\nThis model can now be trained on a labeled dataset using the fit() method and used for making predictions on new, unseen data.","metadata":{}},{"cell_type":"code","source":"model.fit(xr_train_pca,yr_train1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model.fit(xr_train_pca, yr_train1) is used to train the RandomForestClassifier model (model) on the transformed training data (xr_train_pca) and corresponding target values (yr_train1).\n\nHere's a breakdown of the code:\n\nfit(): This method is used in scikit-learn's machine learning models to train the model on the provided training data. It takes the input features (xr_train_pca) and the corresponding target values (yr_train1) as input and adjusts the model's internal parameters to fit the training data.\n\nxr_train_pca: This variable represents the transformed training set of input features obtained through PCA. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a training sample and each column represents a principal component.\n\nyr_train1: This variable represents the corresponding true target values for the training data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the true target values for each training sample.\n\nBy executing model.fit(xr_train_pca, yr_train1), the RandomForestClassifier model is trained on the transformed training data. The model will learn to make predictions based on the relationships between the principal components and the target values.\n\nAfter training, the model's internal parameters will be adjusted to best fit the training data, allowing it to make predictions on new, unseen data.\n\nIt's important to note that the transformed training data (xr_train_pca) should correspond to the same feature space as the original training data used for PCA (xr_train1) to ensure consistency in the dimensionality reduction process.","metadata":{}},{"cell_type":"code","source":"yr_predict_pca = model.predict(xr_test_pca)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code yr_predict_pca = model.predict(xr_test_pca) is used to make predictions using the trained RandomForestClassifier model (model) on the transformed testing data (xr_test_pca).\n\nHere's a breakdown of the code:\n\npredict(): This method is used in scikit-learn's machine learning models to make predictions on new, unseen data. It takes the input features (xr_test_pca) as input and returns the predicted target values.\n\nxr_test_pca: This variable represents the transformed testing set of input features obtained through PCA. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a testing sample and each column represents a principal component.\n\nBy executing yr_predict_pca = model.predict(xr_test_pca), the trained RandomForestClassifier model predicts the target values for the transformed testing data. The model uses the relationships learned during training between the principal components and the target values to make these predictions.\n\nThe predicted target values are stored in the variable yr_predict_pca, which will be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the predicted target values corresponding to each testing sample.\n\nThese predicted values can then be further analyzed, evaluated, or compared with the true target values to assess the performance of the model on the transformed testing data.","metadata":{}},{"cell_type":"code","source":"model_score_r_pca = model.score(xr_test_pca, yr_test1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_score_r_pca = model.score(xr_test_pca, yr_test1) calculates the accuracy score of the RandomForestClassifier model (model) on the transformed testing data (xr_test_pca) and the corresponding true target values (yr_test1).\n\nHere's a breakdown of the code:\n\nscore(): This method is used in scikit-learn's machine learning models to calculate the accuracy score of the model on the given test data. It takes the input features (xr_test_pca) and the corresponding true target values (yr_test1) as input and returns the accuracy score.\n\nxr_test_pca: This variable represents the transformed testing set of input features obtained through PCA. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame, where each row corresponds to a testing sample and each column represents a principal component.\n\nyr_test1: This variable represents the corresponding true target values for the testing data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series, containing the true target values for each testing sample.\n\nBy executing model_score_r_pca = model.score(xr_test_pca, yr_test1), the RandomForestClassifier model predicts the target values for the transformed testing data using the learned relationships between the principal components and the target values. It then compares these predicted values with the true target values and calculates the accuracy score.\n\nThe accuracy score is stored in the variable model_score_r_pca, which represents the proportion of correctly predicted target values to the total number of testing samples.\n\nThis score can be used to assess the performance of the model on the transformed testing data and evaluate its accuracy in predicting the target values.","metadata":{}},{"cell_type":"code","source":"print(model_score_r_pca)\nprint(metrics.classification_report(yr_test1, yr_predict_pca))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The print() function is used to display the information on the console. The accuracy score is printed using the model_score_r_pca variable, which stores the accuracy score calculated using the score() method of the RandomForestClassifier model.\n\nThe classification report is printed using the classification_report() function from the metrics module. It takes the true target values (yr_test1) and the predicted target values (yr_predict_pca) as input and generates a report that includes various evaluation metrics such as precision, recall, F1-score, and support for each class.\n\nBy executing this code, you will see the accuracy score and the classification report printed, providing a summary of the model's performance on the transformed testing data.","metadata":{}},{"cell_type":"markdown","source":"##### With PCA, we couldn't see any better results, hence let's finalise the model which was created by RF Classifier, and save the model so that we can use it in a later stage :)","metadata":{}},{"cell_type":"markdown","source":"#### Pickling the model","metadata":{}},{"cell_type":"code","source":"import pickle","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"filename = 'model.sav'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The pickle module in Python is used for serializing and deserializing Python objects. It allows you to save Python objects (such as models, data, or any other complex data structures) to a file and later load them back into memory.","metadata":{}},{"cell_type":"code","source":"pickle.dump(model_rf_smote, open(filename, 'wb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variable filename in your code snippet 'model.sav' represents the name of the file where you want to save or load the model using the pickle module.","metadata":{}},{"cell_type":"code","source":"load_model = pickle.load(open(filename, 'rb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code load_model = pickle.load(open(filename, 'rb')) loads a saved model from the file specified by the filename variable using the pickle module.\n\nHere's a breakdown of the code:\n\nopen(filename, 'rb'): This code opens the file specified by the filename variable in binary mode ('rb'). The 'rb' mode is used to read the file as binary data.\n\npickle.load(): This function from the pickle module is used to load the saved model from the opened file. It takes the file object as input and returns the loaded model.\n\nload_model: This variable stores the loaded model, which can be used for further operations or predictions.\n\nBy executing load_model = pickle.load(open(filename, 'rb')), the saved model is loaded from the file specified by filename. The file should contain a serialized version of a Python object, such as a trained model, that was saved using the pickle.dump() function.\n\nMake sure that the filename variable contains the correct path and name of the file where the model was saved.","metadata":{}},{"cell_type":"code","source":"model_score_r1 = load_model.score(xr_test1, yr_test1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code model_score_r1 = load_model.score(xr_test1, yr_test1) calculates the accuracy score of a loaded model (load_model) on the test data (xr_test1) and the corresponding true target values (yr_test1).\n\nHere's a breakdown of the code:\n\nscore(): This method is used to calculate the accuracy score of a machine learning model on the given test data. In this case, it is called on the load_model object.\n\nxr_test1: This variable represents the test set of input features on which you want to evaluate the model's performance. It should be a 2-dimensional array-like object, such as a NumPy array or a pandas DataFrame.\n\nyr_test1: This variable represents the corresponding true target values for the test data. It should be a 1-dimensional array-like object, such as a NumPy array or a pandas Series.\n\nBy executing model_score_r1 = load_model.score(xr_test1, yr_test1), the loaded model predicts the target values for the test data (xr_test1) and then compares these predictions with the true target values (yr_test1) to calculate the accuracy score.\n\nThe accuracy score is stored in the variable model_score_r1, which represents the proportion of correctly predicted target values to the total number of test samples.\n\nThis score can be used to assess the performance of the loaded model on the provided test data and evaluate its accuracy in predicting the target values.","metadata":{}},{"cell_type":"code","source":"model_score_r1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variable model_score_r1 represents the accuracy score of the model on the test data. This will display the accuracy score of the model on the test data in the console.","metadata":{}},{"cell_type":"markdown","source":"##### Our final model i.e. RF Classifier with SMOTEENN, is now ready and dumped in model.sav, which we will use and prepare API's so that we can access our model from UI.","metadata":{}}]}